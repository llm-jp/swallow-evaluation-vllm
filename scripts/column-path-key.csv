column,path,key,max_score
gsm8k,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.gsm8k.exact_match,strict-match",1
squad2,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.squadv2.exact,none",100
triviaqa,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.triviaqa.exact_match,remove_whitespace",1
hellaswag,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.hellaswag.acc,none",1
openbookqa,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.openbookqa.acc,none",1
xwinograd_en,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.xwinograd_en.acc,none",1
bbh_cot,en/harness_en/alltasks_3shot_allcases/bbh_cot/results.json,"results.bbh_cot_fewshot.exact_match,get-answer",1
mmlu,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu.acc,none",1
mmlu_social_sciences,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_social_sciences.acc,none",1
mmlu_humanities,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_humanities.acc,none",1
mmlu_stem,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_stem.acc,none",1
mmlu_other,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_other.acc,none",1
gsm8k_8shot_flexible-extract,en/harness_en/alltasks_8shot_gsm8kcases/gsm8k/results.json,"results.gsm8k.exact_match,flexible-extract",1
gsm8k_8shot_strict-match,en/harness_en/alltasks_8shot_gsm8kcases/gsm8k/results.json,"results.gsm8k.exact_match,strict-match",1
gsm8k_8shot_cot_flexible-extract,en/harness_en/alltasks_8shot_gsm8kcases/gsm8k/results.json,"results.gsm8k_cot.exact_match,flexible-extract",1
gsm8k_8shot_cot_strict-match,en/harness_en/alltasks_8shot_gsm8kcases/gsm8k/results.json,"results.gsm8k_cot.exact_match,strict-match",1
